{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "from torchvision.transforms import Compose, ToTensor, Resize, Normalize, RandomHorizontalFlip, RandomRotation\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "Myyf9KOLzz11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_USERNAME'] = 'yourkaggleusername'\n",
        "os.environ['KAGGLE_KEY'] = 'yourkaggleapikey'\n",
        "\n",
        "# Download dataset from Kaggle\n",
        "!kaggle datasets download -d meetnagadia/human-action-recognition-har-dataset --unzip\n",
        "\n",
        "# Clone the repository containing CNN-KAN code\n",
        "!git clone https://github.com/jakariaemon/CNN-KAN.git\n",
        "os.chdir('CNN-KAN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7UmhaVNNBmT",
        "outputId": "ac754358-4352-49e1-dc09-2ab26490e4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/meetnagadia/human-action-recognition-har-dataset\n",
            "License(s): ODbL-1.0\n",
            "Downloading human-action-recognition-har-dataset.zip to /content/CNN-KAN/CNN-KAN\n",
            "100% 296M/297M [00:13<00:00, 25.0MB/s]\n",
            "100% 297M/297M [00:13<00:00, 22.3MB/s]\n",
            "Cloning into 'CNN-KAN'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 21 (delta 4), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (21/21), 11.22 KiB | 11.22 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/CNN-KAN/Human Action Recognition'\n",
        "train_csv_path = os.path.join(data_path, 'Training_set.csv')"
      ],
      "metadata": {
        "id": "jOx-mqWWO2u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from cnn_KAN import KANLinear\n",
        "\n",
        "# custom dataset class for HAR dataset\n",
        "class HARDataset(Dataset):\n",
        "    def __init__(self, root_dir, csv_file, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "\n",
        "        df = pd.read_csv(csv_file)\n",
        "        for _, row in df.iterrows():\n",
        "            img_path = os.path.join(self.root_dir, 'train', row['filename'])\n",
        "            if os.path.isfile(img_path):\n",
        "                self.data.append(img_path)\n",
        "                self.labels.append(row['label'])\n",
        "\n",
        "        # Label mapping\n",
        "        self.label_mapping = {label: idx for idx, label in enumerate(sorted(set(self.labels)))}\n",
        "        self.labels = [self.label_mapping[label] for label in self.labels]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZZmLANfPed6",
        "outputId": "7335db01-ed8d-45a5-d14e-98816f1bcd74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=4096, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n",
            "conv1.weight: 864\n",
            "conv1.bias: 32\n",
            "conv2.weight: 18432\n",
            "conv2.bias: 64\n",
            "fc1.weight: 1048576\n",
            "fc1.bias: 256\n",
            "fc2.weight: 2560\n",
            "fc2.bias: 10\n",
            "Total trainable parameters: 1070794\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             896\n",
            "         MaxPool2d-2           [-1, 32, 16, 16]               0\n",
            "            Conv2d-3           [-1, 64, 16, 16]          18,496\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Linear-5                  [-1, 256]       1,048,832\n",
            "            Linear-6                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 1,070,794\n",
            "Trainable params: 1,070,794\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.47\n",
            "Params size (MB): 4.08\n",
            "Estimated Total Size (MB): 4.57\n",
            "----------------------------------------------------------------\n",
            "conv1.weight: torch.Size([32, 3, 3, 3]) requires_grad\n",
            "conv1.bias: torch.Size([32]) requires_grad\n",
            "conv2.weight: torch.Size([64, 32, 3, 3]) requires_grad\n",
            "conv2.bias: torch.Size([64]) requires_grad\n",
            "fc1.weight: torch.Size([256, 4096]) requires_grad\n",
            "fc1.bias: torch.Size([256]) requires_grad\n",
            "fc2.weight: torch.Size([10, 256]) requires_grad\n",
            "fc2.bias: torch.Size([10]) requires_grad\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.265456\n",
            "Train Epoch: 0 [5000/50000 (10%)]\tLoss: 1.640708\n",
            "Train Epoch: 0 [10000/50000 (20%)]\tLoss: 1.558106\n",
            "Train Epoch: 0 [15000/50000 (30%)]\tLoss: 1.520911\n",
            "Train Epoch: 0 [20000/50000 (40%)]\tLoss: 1.411631\n",
            "Train Epoch: 0 [25000/50000 (50%)]\tLoss: 1.389274\n",
            "Train Epoch: 0 [30000/50000 (60%)]\tLoss: 1.323953\n",
            "Train Epoch: 0 [35000/50000 (70%)]\tLoss: 1.257234\n",
            "Train Epoch: 0 [40000/50000 (80%)]\tLoss: 1.290607\n",
            "Train Epoch: 0 [45000/50000 (90%)]\tLoss: 1.210230\n",
            "\n",
            "Test set: Average loss: 0.0047, Accuracy: 5833/10000 (58%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = Compose([\n",
        "    Resize((224, 224)),\n",
        "    ToTensor(),\n",
        "    Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# Prepare Dataset and DataLoader\n",
        "train_dataset = HARDataset(root_dir=data_path, csv_file=train_csv_path, transform=transform)\n",
        "test_dataset = HARDataset(root_dir=data_path, csv_file=train_csv_path, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "ulaA3P8RPnpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetKAN(nn.Module):\n",
        "    def __init__(self, num_classes=15):\n",
        "        super(ResNetKAN, self).__init__()\n",
        "        # Load a pretrained ResNet model\n",
        "        resnet = models.resnet101(pretrained=True)\n",
        "        self.resnet_features = nn.Sequential(*list(resnet.children())[:-2])  # Remove the last FC layer\n",
        "\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # KAN Layers\n",
        "        self.kan1 = KANLinear(2048, 256)\n",
        "        self.kan2 = KANLinear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet_features(x)\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten for KAN input\n",
        "        x = self.kan1(x)\n",
        "        x = self.kan2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ResNetKAN(num_classes=len(train_dataset.label_mapping)).to(device)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-3)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBr_A_4CPzh4",
        "outputId": "04d6a877-cf6c-4115-f2e4-9e5618c003e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "    return running_loss / len(train_loader)\n",
        "\n",
        "def evaluate(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
        "    return test_loss"
      ],
      "metadata": {
        "id": "oPwcjCXoP3dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3):\n",
        "    train_loss = train(model, device, train_loader, optimizer, epoch)\n",
        "    test_loss = evaluate(model, device, test_loader)\n",
        "    scheduler.step(test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZMQCEunP7_U",
        "outputId": "02407f37-5809-4e50-bdfa-58b9cbb98626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/12600 (0%)]\tLoss: 2.689581\n",
            "Train Epoch: 0 [320/12600 (3%)]\tLoss: 2.574656\n",
            "Train Epoch: 0 [640/12600 (5%)]\tLoss: 2.365435\n",
            "Train Epoch: 0 [960/12600 (8%)]\tLoss: 2.125955\n",
            "Train Epoch: 0 [1280/12600 (10%)]\tLoss: 2.079260\n",
            "Train Epoch: 0 [1600/12600 (13%)]\tLoss: 1.775713\n",
            "Train Epoch: 0 [1920/12600 (15%)]\tLoss: 1.679043\n",
            "Train Epoch: 0 [2240/12600 (18%)]\tLoss: 1.706814\n",
            "Train Epoch: 0 [2560/12600 (20%)]\tLoss: 1.584020\n",
            "Train Epoch: 0 [2880/12600 (23%)]\tLoss: 1.146715\n",
            "Train Epoch: 0 [3200/12600 (25%)]\tLoss: 1.226723\n",
            "Train Epoch: 0 [3520/12600 (28%)]\tLoss: 1.407863\n",
            "Train Epoch: 0 [3840/12600 (30%)]\tLoss: 1.062788\n",
            "Train Epoch: 0 [4160/12600 (33%)]\tLoss: 1.233393\n",
            "Train Epoch: 0 [4480/12600 (36%)]\tLoss: 0.861074\n",
            "Train Epoch: 0 [4800/12600 (38%)]\tLoss: 1.024711\n",
            "Train Epoch: 0 [5120/12600 (41%)]\tLoss: 0.905216\n",
            "Train Epoch: 0 [5440/12600 (43%)]\tLoss: 0.945872\n",
            "Train Epoch: 0 [5760/12600 (46%)]\tLoss: 0.887265\n",
            "Train Epoch: 0 [6080/12600 (48%)]\tLoss: 0.671156\n",
            "Train Epoch: 0 [6400/12600 (51%)]\tLoss: 0.910222\n",
            "Train Epoch: 0 [6720/12600 (53%)]\tLoss: 0.928933\n",
            "Train Epoch: 0 [7040/12600 (56%)]\tLoss: 0.952581\n",
            "Train Epoch: 0 [7360/12600 (58%)]\tLoss: 0.734240\n",
            "Train Epoch: 0 [7680/12600 (61%)]\tLoss: 0.672077\n",
            "Train Epoch: 0 [8000/12600 (63%)]\tLoss: 0.770347\n",
            "Train Epoch: 0 [8320/12600 (66%)]\tLoss: 1.107938\n",
            "Train Epoch: 0 [8640/12600 (69%)]\tLoss: 0.956332\n",
            "Train Epoch: 0 [8960/12600 (71%)]\tLoss: 0.717233\n",
            "Train Epoch: 0 [9280/12600 (74%)]\tLoss: 0.919116\n",
            "Train Epoch: 0 [9600/12600 (76%)]\tLoss: 0.634025\n",
            "Train Epoch: 0 [9920/12600 (79%)]\tLoss: 0.758379\n",
            "Train Epoch: 0 [10240/12600 (81%)]\tLoss: 0.767182\n",
            "Train Epoch: 0 [10560/12600 (84%)]\tLoss: 1.045683\n",
            "Train Epoch: 0 [10880/12600 (86%)]\tLoss: 0.579183\n",
            "Train Epoch: 0 [11200/12600 (89%)]\tLoss: 1.087542\n",
            "Train Epoch: 0 [11520/12600 (91%)]\tLoss: 0.598904\n",
            "Train Epoch: 0 [11840/12600 (94%)]\tLoss: 1.232854\n",
            "Train Epoch: 0 [12160/12600 (96%)]\tLoss: 0.607013\n",
            "Train Epoch: 0 [12480/12600 (99%)]\tLoss: 0.765120\n",
            "\n",
            "Test set: Average loss: 0.0124, Accuracy: 11190/12600 (89%)\n",
            "\n",
            "Train Epoch: 1 [0/12600 (0%)]\tLoss: 0.801190\n",
            "Train Epoch: 1 [320/12600 (3%)]\tLoss: 0.458597\n",
            "Train Epoch: 1 [640/12600 (5%)]\tLoss: 0.322251\n",
            "Train Epoch: 1 [960/12600 (8%)]\tLoss: 0.198417\n",
            "Train Epoch: 1 [1280/12600 (10%)]\tLoss: 0.349840\n",
            "Train Epoch: 1 [1600/12600 (13%)]\tLoss: 0.386045\n",
            "Train Epoch: 1 [1920/12600 (15%)]\tLoss: 0.416294\n",
            "Train Epoch: 1 [2240/12600 (18%)]\tLoss: 0.254511\n",
            "Train Epoch: 1 [2560/12600 (20%)]\tLoss: 0.224608\n",
            "Train Epoch: 1 [2880/12600 (23%)]\tLoss: 0.439586\n",
            "Train Epoch: 1 [3200/12600 (25%)]\tLoss: 0.692499\n",
            "Train Epoch: 1 [3520/12600 (28%)]\tLoss: 0.270099\n",
            "Train Epoch: 1 [3840/12600 (30%)]\tLoss: 0.433738\n",
            "Train Epoch: 1 [4160/12600 (33%)]\tLoss: 0.588810\n",
            "Train Epoch: 1 [4480/12600 (36%)]\tLoss: 0.506996\n",
            "Train Epoch: 1 [4800/12600 (38%)]\tLoss: 0.349587\n",
            "Train Epoch: 1 [5120/12600 (41%)]\tLoss: 0.359471\n",
            "Train Epoch: 1 [5440/12600 (43%)]\tLoss: 0.366101\n",
            "Train Epoch: 1 [5760/12600 (46%)]\tLoss: 0.292335\n",
            "Train Epoch: 1 [6080/12600 (48%)]\tLoss: 0.304900\n",
            "Train Epoch: 1 [6400/12600 (51%)]\tLoss: 0.393809\n",
            "Train Epoch: 1 [6720/12600 (53%)]\tLoss: 0.349796\n",
            "Train Epoch: 1 [7040/12600 (56%)]\tLoss: 0.364168\n",
            "Train Epoch: 1 [7360/12600 (58%)]\tLoss: 0.596810\n",
            "Train Epoch: 1 [7680/12600 (61%)]\tLoss: 0.320225\n",
            "Train Epoch: 1 [8000/12600 (63%)]\tLoss: 0.274521\n",
            "Train Epoch: 1 [8320/12600 (66%)]\tLoss: 0.344217\n",
            "Train Epoch: 1 [8640/12600 (69%)]\tLoss: 0.345376\n",
            "Train Epoch: 1 [8960/12600 (71%)]\tLoss: 0.224926\n",
            "Train Epoch: 1 [9280/12600 (74%)]\tLoss: 0.383270\n",
            "Train Epoch: 1 [9600/12600 (76%)]\tLoss: 0.319711\n",
            "Train Epoch: 1 [9920/12600 (79%)]\tLoss: 0.302808\n",
            "Train Epoch: 1 [10240/12600 (81%)]\tLoss: 0.262171\n",
            "Train Epoch: 1 [10560/12600 (84%)]\tLoss: 0.719070\n",
            "Train Epoch: 1 [10880/12600 (86%)]\tLoss: 0.634185\n",
            "Train Epoch: 1 [11200/12600 (89%)]\tLoss: 0.249828\n",
            "Train Epoch: 1 [11520/12600 (91%)]\tLoss: 0.417663\n",
            "Train Epoch: 1 [11840/12600 (94%)]\tLoss: 0.454266\n",
            "Train Epoch: 1 [12160/12600 (96%)]\tLoss: 0.169863\n",
            "Train Epoch: 1 [12480/12600 (99%)]\tLoss: 0.328432\n",
            "\n",
            "Test set: Average loss: 0.0047, Accuracy: 12117/12600 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/12600 (0%)]\tLoss: 0.230558\n",
            "Train Epoch: 2 [320/12600 (3%)]\tLoss: 0.161086\n",
            "Train Epoch: 2 [640/12600 (5%)]\tLoss: 0.161880\n",
            "Train Epoch: 2 [960/12600 (8%)]\tLoss: 0.142915\n",
            "Train Epoch: 2 [1280/12600 (10%)]\tLoss: 0.135009\n",
            "Train Epoch: 2 [1600/12600 (13%)]\tLoss: 0.242867\n",
            "Train Epoch: 2 [1920/12600 (15%)]\tLoss: 0.206056\n",
            "Train Epoch: 2 [2240/12600 (18%)]\tLoss: 0.070593\n",
            "Train Epoch: 2 [2560/12600 (20%)]\tLoss: 0.291141\n",
            "Train Epoch: 2 [2880/12600 (23%)]\tLoss: 0.137296\n",
            "Train Epoch: 2 [3200/12600 (25%)]\tLoss: 0.192253\n",
            "Train Epoch: 2 [3520/12600 (28%)]\tLoss: 0.173999\n",
            "Train Epoch: 2 [3840/12600 (30%)]\tLoss: 0.271356\n",
            "Train Epoch: 2 [4160/12600 (33%)]\tLoss: 0.193519\n",
            "Train Epoch: 2 [4480/12600 (36%)]\tLoss: 0.124992\n",
            "Train Epoch: 2 [4800/12600 (38%)]\tLoss: 0.146799\n",
            "Train Epoch: 2 [5120/12600 (41%)]\tLoss: 0.208171\n",
            "Train Epoch: 2 [5440/12600 (43%)]\tLoss: 0.065753\n",
            "Train Epoch: 2 [5760/12600 (46%)]\tLoss: 0.072474\n",
            "Train Epoch: 2 [6080/12600 (48%)]\tLoss: 0.134990\n",
            "Train Epoch: 2 [6400/12600 (51%)]\tLoss: 0.322420\n",
            "Train Epoch: 2 [6720/12600 (53%)]\tLoss: 0.142020\n",
            "Train Epoch: 2 [7040/12600 (56%)]\tLoss: 0.083667\n",
            "Train Epoch: 2 [7360/12600 (58%)]\tLoss: 0.104442\n",
            "Train Epoch: 2 [7680/12600 (61%)]\tLoss: 0.059333\n",
            "Train Epoch: 2 [8000/12600 (63%)]\tLoss: 0.049244\n",
            "Train Epoch: 2 [8320/12600 (66%)]\tLoss: 0.062300\n",
            "Train Epoch: 2 [8640/12600 (69%)]\tLoss: 0.129883\n",
            "Train Epoch: 2 [8960/12600 (71%)]\tLoss: 0.199140\n",
            "Train Epoch: 2 [9280/12600 (74%)]\tLoss: 0.288200\n",
            "Train Epoch: 2 [9600/12600 (76%)]\tLoss: 0.160400\n",
            "Train Epoch: 2 [9920/12600 (79%)]\tLoss: 0.133522\n",
            "Train Epoch: 2 [10240/12600 (81%)]\tLoss: 0.413177\n",
            "Train Epoch: 2 [10560/12600 (84%)]\tLoss: 0.210549\n",
            "Train Epoch: 2 [10880/12600 (86%)]\tLoss: 0.263931\n",
            "Train Epoch: 2 [11200/12600 (89%)]\tLoss: 0.020273\n",
            "Train Epoch: 2 [11520/12600 (91%)]\tLoss: 0.312527\n",
            "Train Epoch: 2 [11840/12600 (94%)]\tLoss: 0.053269\n",
            "Train Epoch: 2 [12160/12600 (96%)]\tLoss: 0.138232\n",
            "Train Epoch: 2 [12480/12600 (99%)]\tLoss: 0.271356\n",
            "\n",
            "Test set: Average loss: 0.0016, Accuracy: 12444/12600 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(model, device, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "            all_predictions.extend(pred.cpu().numpy().flatten())\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "\n",
        "    all_targets = np.array(all_targets)\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    rmse = np.sqrt(mean_squared_error(all_targets, all_predictions))\n",
        "    mae = mean_absolute_error(all_targets, all_predictions)\n",
        "\n",
        "    print(f'\\nOverall Accuracy: {accuracy:.2f}%')\n",
        "    print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
        "    print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
        "\n",
        "    return accuracy, rmse, mae\n"
      ],
      "metadata": {
        "id": "M2E2kVYuP6Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, rmse, mae = calculate_metrics(model, device, test_loader)"
      ],
      "metadata": {
        "id": "4SstIPkoPaFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "615010bb-d8bc-487d-e2e7-132679635e78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall Accuracy: 98.76%\n",
            "Root Mean Squared Error (RMSE): 0.7234\n",
            "Mean Absolute Error (MAE): 0.0690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rhrIGwBxQBs-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}