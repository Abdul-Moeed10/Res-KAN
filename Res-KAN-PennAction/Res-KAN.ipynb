{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "from torchvision.transforms import Compose, ToTensor, Resize, Normalize\n",
        "from PIL import Image\n",
        "import scipy.io as sio\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# using google drive due to the size of the dataset and for easy integration with Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_zip = '/content/drive/My Drive/data.zip'\n",
        "output_dir = '/content/data'\n",
        "\n",
        "with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_dir)\n",
        "\n",
        "!git clone https://github.com/jakariaemon/CNN-KAN.git\n",
        "os.chdir('CNN-KAN')\n",
        "\n",
        "from cnn_KAN import KANLinear"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myyf9KOLzz11",
        "outputId": "7d47d6e6-51a3-43dc-93f9-e4c9a95a7ed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'CNN-KAN'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 21 (delta 4), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (21/21), 11.22 KiB | 11.22 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "CNN(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=4096, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n",
            "conv1.weight: 864\n",
            "conv1.bias: 32\n",
            "conv2.weight: 18432\n",
            "conv2.bias: 64\n",
            "fc1.weight: 1048576\n",
            "fc1.bias: 256\n",
            "fc2.weight: 2560\n",
            "fc2.bias: 10\n",
            "Total trainable parameters: 1070794\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             896\n",
            "         MaxPool2d-2           [-1, 32, 16, 16]               0\n",
            "            Conv2d-3           [-1, 64, 16, 16]          18,496\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Linear-5                  [-1, 256]       1,048,832\n",
            "            Linear-6                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 1,070,794\n",
            "Trainable params: 1,070,794\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.47\n",
            "Params size (MB): 4.08\n",
            "Estimated Total Size (MB): 4.57\n",
            "----------------------------------------------------------------\n",
            "conv1.weight: torch.Size([32, 3, 3, 3]) requires_grad\n",
            "conv1.bias: torch.Size([32]) requires_grad\n",
            "conv2.weight: torch.Size([64, 32, 3, 3]) requires_grad\n",
            "conv2.bias: torch.Size([64]) requires_grad\n",
            "fc1.weight: torch.Size([256, 4096]) requires_grad\n",
            "fc1.bias: torch.Size([256]) requires_grad\n",
            "fc2.weight: torch.Size([10, 256]) requires_grad\n",
            "fc2.bias: torch.Size([10]) requires_grad\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:01<00:00, 86.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.318652\n",
            "Train Epoch: 0 [5000/50000 (10%)]\tLoss: 1.795677\n",
            "Train Epoch: 0 [10000/50000 (20%)]\tLoss: 1.601825\n",
            "Train Epoch: 0 [15000/50000 (30%)]\tLoss: 1.525488\n",
            "Train Epoch: 0 [20000/50000 (40%)]\tLoss: 1.455574\n",
            "Train Epoch: 0 [25000/50000 (50%)]\tLoss: 1.305116\n",
            "Train Epoch: 0 [30000/50000 (60%)]\tLoss: 1.229205\n",
            "Train Epoch: 0 [35000/50000 (70%)]\tLoss: 1.349668\n",
            "Train Epoch: 0 [40000/50000 (80%)]\tLoss: 1.199915\n",
            "Train Epoch: 0 [45000/50000 (90%)]\tLoss: 1.284958\n",
            "\n",
            "Test set: Average loss: 0.0047, Accuracy: 5933/10000 (59%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cnn_KAN import KANLinear\n",
        "\n",
        "# Define Label Mapping\n",
        "label_mapping = {\n",
        "    'tennis_serve': 0,\n",
        "    'golf_swing': 1,\n",
        "    'baseball_pitch': 2,\n",
        "    'bench_press': 3,\n",
        "    'pullup': 4,\n",
        "    'pushup': 5,\n",
        "    'situp': 6,\n",
        "    'jumping_jacks': 7,\n",
        "    'strum_guitar': 8,\n",
        "    'bowl': 9,\n",
        "    'tennis_forehand': 10,\n",
        "    'squat': 11,\n",
        "    'jump_rope': 12,\n",
        "    'clean_and_jerk': 13,\n",
        "    'baseball_swing': 14\n",
        "}\n",
        "\n",
        "# Custom Dataset for Penn Action\n",
        "class PennActionDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.frames_dir = os.path.join(root_dir, 'frames')\n",
        "        self.labels_dir = os.path.join(root_dir, 'labels')\n",
        "        self.samples = []\n",
        "\n",
        "        for label_file in os.listdir(self.labels_dir):\n",
        "            label_path = os.path.join(self.labels_dir, label_file)\n",
        "            mat = sio.loadmat(label_path)\n",
        "            action_label = mat['action'][0]\n",
        "            if action_label in label_mapping:\n",
        "                action_index = label_mapping[action_label]\n",
        "                sequence_id = label_file.split('.')[0]\n",
        "                frame_dir = os.path.join(self.frames_dir, sequence_id)\n",
        "                frames = sorted(os.listdir(frame_dir))\n",
        "                self.samples.extend([(os.path.join(frame_dir, frame), action_index) for frame in frames])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame_path, label = self.samples[idx]\n",
        "        image = Image.open(frame_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "transform = Compose([\n",
        "    Resize((224, 224)),  #ResNet requires input size of 224x224\n",
        "    ToTensor(),\n",
        "    Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # ImageNet mean and std\n",
        "])\n",
        "\n",
        "train_dataset = PennActionDataset(root_dir='/content/data/data/Penn_Action/Penn_Action', transform=transform)\n",
        "test_dataset = PennActionDataset(root_dir='/content/data/data/Penn_Action/Penn_Action', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the CNN-KAN Model with ResNet Backbone\n",
        "class ResNetKAN(nn.Module):\n",
        "    def __init__(self, num_classes=15):\n",
        "        super(ResNetKAN, self).__init__()\n",
        "        # Load a pretrained ResNet model\n",
        "        resnet = models.resnet101(pretrained=True)\n",
        "        self.resnet_features = nn.Sequential(*list(resnet.children())[:-2])  # Remove the last FC layer\n",
        "\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # KAN Layers\n",
        "        self.kan1 = KANLinear(2048, 256)\n",
        "        self.kan2 = KANLinear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet_features(x)\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten for KAN input\n",
        "        x = self.kan1(x)\n",
        "        x = self.kan2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ResNetKAN(num_classes=len(label_mapping)).to(device)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "def evaluate(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
        "\n",
        "for epoch in range(3):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    evaluate(model, device, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sMnSg-wz08j",
        "outputId": "15148438-8363-4416-b439-4142b8ee609f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:00<00:00, 205MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/163841 (0%)]\tLoss: 2.710208\n",
            "Train Epoch: 0 [640/163841 (0%)]\tLoss: 1.799654\n",
            "Train Epoch: 0 [1280/163841 (1%)]\tLoss: 1.413467\n",
            "Train Epoch: 0 [1920/163841 (1%)]\tLoss: 1.380445\n",
            "Train Epoch: 0 [2560/163841 (2%)]\tLoss: 1.167715\n",
            "Train Epoch: 0 [3200/163841 (2%)]\tLoss: 1.127300\n",
            "Train Epoch: 0 [3840/163841 (2%)]\tLoss: 1.069037\n",
            "Train Epoch: 0 [4480/163841 (3%)]\tLoss: 0.826289\n",
            "Train Epoch: 0 [5120/163841 (3%)]\tLoss: 0.853000\n",
            "Train Epoch: 0 [5760/163841 (4%)]\tLoss: 1.087514\n",
            "Train Epoch: 0 [6400/163841 (4%)]\tLoss: 0.870080\n",
            "Train Epoch: 0 [7040/163841 (4%)]\tLoss: 0.620670\n",
            "Train Epoch: 0 [7680/163841 (5%)]\tLoss: 0.620008\n",
            "Train Epoch: 0 [8320/163841 (5%)]\tLoss: 0.909061\n",
            "Train Epoch: 0 [8960/163841 (5%)]\tLoss: 0.675425\n",
            "Train Epoch: 0 [9600/163841 (6%)]\tLoss: 0.778523\n",
            "Train Epoch: 0 [10240/163841 (6%)]\tLoss: 0.768870\n",
            "Train Epoch: 0 [10880/163841 (7%)]\tLoss: 0.443736\n",
            "Train Epoch: 0 [11520/163841 (7%)]\tLoss: 0.605259\n",
            "Train Epoch: 0 [12160/163841 (7%)]\tLoss: 0.442398\n",
            "Train Epoch: 0 [12800/163841 (8%)]\tLoss: 0.574300\n",
            "Train Epoch: 0 [13440/163841 (8%)]\tLoss: 0.581278\n",
            "Train Epoch: 0 [14080/163841 (9%)]\tLoss: 0.440231\n",
            "Train Epoch: 0 [14720/163841 (9%)]\tLoss: 0.346072\n",
            "Train Epoch: 0 [15360/163841 (9%)]\tLoss: 0.503139\n",
            "Train Epoch: 0 [16000/163841 (10%)]\tLoss: 0.387306\n",
            "Train Epoch: 0 [16640/163841 (10%)]\tLoss: 0.577694\n",
            "Train Epoch: 0 [17280/163841 (11%)]\tLoss: 0.517527\n",
            "Train Epoch: 0 [17920/163841 (11%)]\tLoss: 0.291677\n",
            "Train Epoch: 0 [18560/163841 (11%)]\tLoss: 0.382102\n",
            "Train Epoch: 0 [19200/163841 (12%)]\tLoss: 0.317233\n",
            "Train Epoch: 0 [19840/163841 (12%)]\tLoss: 0.372599\n",
            "Train Epoch: 0 [20480/163841 (12%)]\tLoss: 0.574803\n",
            "Train Epoch: 0 [21120/163841 (13%)]\tLoss: 0.408294\n",
            "Train Epoch: 0 [21760/163841 (13%)]\tLoss: 0.418193\n",
            "Train Epoch: 0 [22400/163841 (14%)]\tLoss: 0.483254\n",
            "Train Epoch: 0 [23040/163841 (14%)]\tLoss: 0.684776\n",
            "Train Epoch: 0 [23680/163841 (14%)]\tLoss: 0.329197\n",
            "Train Epoch: 0 [24320/163841 (15%)]\tLoss: 0.404531\n",
            "Train Epoch: 0 [24960/163841 (15%)]\tLoss: 0.590056\n",
            "Train Epoch: 0 [25600/163841 (16%)]\tLoss: 0.338414\n",
            "Train Epoch: 0 [26240/163841 (16%)]\tLoss: 0.247894\n",
            "Train Epoch: 0 [26880/163841 (16%)]\tLoss: 0.262293\n",
            "Train Epoch: 0 [27520/163841 (17%)]\tLoss: 0.279583\n",
            "Train Epoch: 0 [28160/163841 (17%)]\tLoss: 0.257653\n",
            "Train Epoch: 0 [28800/163841 (18%)]\tLoss: 0.238916\n",
            "Train Epoch: 0 [29440/163841 (18%)]\tLoss: 0.340320\n",
            "Train Epoch: 0 [30080/163841 (18%)]\tLoss: 0.248175\n",
            "Train Epoch: 0 [30720/163841 (19%)]\tLoss: 0.270804\n",
            "Train Epoch: 0 [31360/163841 (19%)]\tLoss: 0.369602\n",
            "Train Epoch: 0 [32000/163841 (20%)]\tLoss: 0.199074\n",
            "Train Epoch: 0 [32640/163841 (20%)]\tLoss: 0.320972\n",
            "Train Epoch: 0 [33280/163841 (20%)]\tLoss: 0.386088\n",
            "Train Epoch: 0 [33920/163841 (21%)]\tLoss: 0.389420\n",
            "Train Epoch: 0 [34560/163841 (21%)]\tLoss: 0.335077\n",
            "Train Epoch: 0 [35200/163841 (21%)]\tLoss: 0.419890\n",
            "Train Epoch: 0 [35840/163841 (22%)]\tLoss: 0.158084\n",
            "Train Epoch: 0 [36480/163841 (22%)]\tLoss: 0.193668\n",
            "Train Epoch: 0 [37120/163841 (23%)]\tLoss: 0.106532\n",
            "Train Epoch: 0 [37760/163841 (23%)]\tLoss: 0.174701\n",
            "Train Epoch: 0 [38400/163841 (23%)]\tLoss: 0.270501\n",
            "Train Epoch: 0 [39040/163841 (24%)]\tLoss: 0.254642\n",
            "Train Epoch: 0 [39680/163841 (24%)]\tLoss: 0.311178\n",
            "Train Epoch: 0 [40320/163841 (25%)]\tLoss: 0.217433\n",
            "Train Epoch: 0 [40960/163841 (25%)]\tLoss: 0.424045\n",
            "Train Epoch: 0 [41600/163841 (25%)]\tLoss: 0.218041\n",
            "Train Epoch: 0 [42240/163841 (26%)]\tLoss: 0.314729\n",
            "Train Epoch: 0 [42880/163841 (26%)]\tLoss: 0.194145\n",
            "Train Epoch: 0 [43520/163841 (27%)]\tLoss: 0.101497\n",
            "Train Epoch: 0 [44160/163841 (27%)]\tLoss: 0.316801\n",
            "Train Epoch: 0 [44800/163841 (27%)]\tLoss: 0.113209\n",
            "Train Epoch: 0 [45440/163841 (28%)]\tLoss: 0.182776\n",
            "Train Epoch: 0 [46080/163841 (28%)]\tLoss: 0.236514\n",
            "Train Epoch: 0 [46720/163841 (29%)]\tLoss: 0.071685\n",
            "Train Epoch: 0 [47360/163841 (29%)]\tLoss: 0.151269\n",
            "Train Epoch: 0 [48000/163841 (29%)]\tLoss: 0.072061\n",
            "Train Epoch: 0 [48640/163841 (30%)]\tLoss: 0.270228\n",
            "Train Epoch: 0 [49280/163841 (30%)]\tLoss: 0.315779\n",
            "Train Epoch: 0 [49920/163841 (30%)]\tLoss: 0.216235\n",
            "Train Epoch: 0 [50560/163841 (31%)]\tLoss: 0.372822\n",
            "Train Epoch: 0 [51200/163841 (31%)]\tLoss: 0.275910\n",
            "Train Epoch: 0 [51840/163841 (32%)]\tLoss: 0.187068\n",
            "Train Epoch: 0 [52480/163841 (32%)]\tLoss: 0.154474\n",
            "Train Epoch: 0 [53120/163841 (32%)]\tLoss: 0.501980\n",
            "Train Epoch: 0 [53760/163841 (33%)]\tLoss: 0.112376\n",
            "Train Epoch: 0 [54400/163841 (33%)]\tLoss: 0.061124\n",
            "Train Epoch: 0 [55040/163841 (34%)]\tLoss: 0.160532\n",
            "Train Epoch: 0 [55680/163841 (34%)]\tLoss: 0.134513\n",
            "Train Epoch: 0 [56320/163841 (34%)]\tLoss: 0.079539\n",
            "Train Epoch: 0 [56960/163841 (35%)]\tLoss: 0.231125\n",
            "Train Epoch: 0 [57600/163841 (35%)]\tLoss: 0.323098\n",
            "Train Epoch: 0 [58240/163841 (36%)]\tLoss: 0.139114\n",
            "Train Epoch: 0 [58880/163841 (36%)]\tLoss: 0.186539\n",
            "Train Epoch: 0 [59520/163841 (36%)]\tLoss: 0.085454\n",
            "Train Epoch: 0 [60160/163841 (37%)]\tLoss: 0.238081\n",
            "Train Epoch: 0 [60800/163841 (37%)]\tLoss: 0.144272\n",
            "Train Epoch: 0 [61440/163841 (37%)]\tLoss: 0.143808\n",
            "Train Epoch: 0 [62080/163841 (38%)]\tLoss: 0.269619\n",
            "Train Epoch: 0 [62720/163841 (38%)]\tLoss: 0.145649\n",
            "Train Epoch: 0 [63360/163841 (39%)]\tLoss: 0.096030\n",
            "Train Epoch: 0 [64000/163841 (39%)]\tLoss: 0.184103\n",
            "Train Epoch: 0 [64640/163841 (39%)]\tLoss: 0.166788\n",
            "Train Epoch: 0 [65280/163841 (40%)]\tLoss: 0.215255\n",
            "Train Epoch: 0 [65920/163841 (40%)]\tLoss: 0.096228\n",
            "Train Epoch: 0 [66560/163841 (41%)]\tLoss: 0.172812\n",
            "Train Epoch: 0 [67200/163841 (41%)]\tLoss: 0.143846\n",
            "Train Epoch: 0 [67840/163841 (41%)]\tLoss: 0.165083\n",
            "Train Epoch: 0 [68480/163841 (42%)]\tLoss: 0.064316\n",
            "Train Epoch: 0 [69120/163841 (42%)]\tLoss: 0.256462\n",
            "Train Epoch: 0 [69760/163841 (43%)]\tLoss: 0.390394\n",
            "Train Epoch: 0 [70400/163841 (43%)]\tLoss: 0.023061\n",
            "Train Epoch: 0 [71040/163841 (43%)]\tLoss: 0.077657\n",
            "Train Epoch: 0 [71680/163841 (44%)]\tLoss: 0.035679\n",
            "Train Epoch: 0 [72320/163841 (44%)]\tLoss: 0.046046\n",
            "Train Epoch: 0 [72960/163841 (45%)]\tLoss: 0.184723\n",
            "Train Epoch: 0 [73600/163841 (45%)]\tLoss: 0.097670\n",
            "Train Epoch: 0 [74240/163841 (45%)]\tLoss: 0.052476\n",
            "Train Epoch: 0 [74880/163841 (46%)]\tLoss: 0.041158\n",
            "Train Epoch: 0 [75520/163841 (46%)]\tLoss: 0.200459\n",
            "Train Epoch: 0 [76160/163841 (46%)]\tLoss: 0.128310\n",
            "Train Epoch: 0 [76800/163841 (47%)]\tLoss: 0.135227\n",
            "Train Epoch: 0 [77440/163841 (47%)]\tLoss: 0.247798\n",
            "Train Epoch: 0 [78080/163841 (48%)]\tLoss: 0.054594\n",
            "Train Epoch: 0 [78720/163841 (48%)]\tLoss: 0.074195\n",
            "Train Epoch: 0 [79360/163841 (48%)]\tLoss: 0.200419\n",
            "Train Epoch: 0 [80000/163841 (49%)]\tLoss: 0.341280\n",
            "Train Epoch: 0 [80640/163841 (49%)]\tLoss: 0.189777\n",
            "Train Epoch: 0 [81280/163841 (50%)]\tLoss: 0.174555\n",
            "Train Epoch: 0 [81920/163841 (50%)]\tLoss: 0.132887\n",
            "Train Epoch: 0 [82560/163841 (50%)]\tLoss: 0.123238\n",
            "Train Epoch: 0 [83200/163841 (51%)]\tLoss: 0.058357\n",
            "Train Epoch: 0 [83840/163841 (51%)]\tLoss: 0.097336\n",
            "Train Epoch: 0 [84480/163841 (52%)]\tLoss: 0.074288\n",
            "Train Epoch: 0 [85120/163841 (52%)]\tLoss: 0.108360\n",
            "Train Epoch: 0 [85760/163841 (52%)]\tLoss: 0.011939\n",
            "Train Epoch: 0 [86400/163841 (53%)]\tLoss: 0.014636\n",
            "Train Epoch: 0 [87040/163841 (53%)]\tLoss: 0.048849\n",
            "Train Epoch: 0 [87680/163841 (53%)]\tLoss: 0.154668\n",
            "Train Epoch: 0 [88320/163841 (54%)]\tLoss: 0.036650\n",
            "Train Epoch: 0 [88960/163841 (54%)]\tLoss: 0.055823\n",
            "Train Epoch: 0 [89600/163841 (55%)]\tLoss: 0.154787\n",
            "Train Epoch: 0 [90240/163841 (55%)]\tLoss: 0.011045\n",
            "Train Epoch: 0 [90880/163841 (55%)]\tLoss: 0.141088\n",
            "Train Epoch: 0 [91520/163841 (56%)]\tLoss: 0.017763\n",
            "Train Epoch: 0 [92160/163841 (56%)]\tLoss: 0.037668\n",
            "Train Epoch: 0 [92800/163841 (57%)]\tLoss: 0.037346\n",
            "Train Epoch: 0 [93440/163841 (57%)]\tLoss: 0.402483\n",
            "Train Epoch: 0 [94080/163841 (57%)]\tLoss: 0.037290\n",
            "Train Epoch: 0 [94720/163841 (58%)]\tLoss: 0.030206\n",
            "Train Epoch: 0 [95360/163841 (58%)]\tLoss: 0.038808\n",
            "Train Epoch: 0 [96000/163841 (59%)]\tLoss: 0.062746\n",
            "Train Epoch: 0 [96640/163841 (59%)]\tLoss: 0.056854\n",
            "Train Epoch: 0 [97280/163841 (59%)]\tLoss: 0.133136\n",
            "Train Epoch: 0 [97920/163841 (60%)]\tLoss: 0.033011\n",
            "Train Epoch: 0 [98560/163841 (60%)]\tLoss: 0.021734\n",
            "Train Epoch: 0 [99200/163841 (61%)]\tLoss: 0.035011\n",
            "Train Epoch: 0 [99840/163841 (61%)]\tLoss: 0.172093\n",
            "Train Epoch: 0 [100480/163841 (61%)]\tLoss: 0.043864\n",
            "Train Epoch: 0 [101120/163841 (62%)]\tLoss: 0.127691\n",
            "Train Epoch: 0 [101760/163841 (62%)]\tLoss: 0.087411\n",
            "Train Epoch: 0 [102400/163841 (62%)]\tLoss: 0.035934\n",
            "Train Epoch: 0 [103040/163841 (63%)]\tLoss: 0.100206\n",
            "Train Epoch: 0 [103680/163841 (63%)]\tLoss: 0.057562\n",
            "Train Epoch: 0 [104320/163841 (64%)]\tLoss: 0.019409\n",
            "Train Epoch: 0 [104960/163841 (64%)]\tLoss: 0.078976\n",
            "Train Epoch: 0 [105600/163841 (64%)]\tLoss: 0.074419\n",
            "Train Epoch: 0 [106240/163841 (65%)]\tLoss: 0.028873\n",
            "Train Epoch: 0 [106880/163841 (65%)]\tLoss: 0.048575\n",
            "Train Epoch: 0 [107520/163841 (66%)]\tLoss: 0.044990\n",
            "Train Epoch: 0 [108160/163841 (66%)]\tLoss: 0.084283\n",
            "Train Epoch: 0 [108800/163841 (66%)]\tLoss: 0.024432\n",
            "Train Epoch: 0 [109440/163841 (67%)]\tLoss: 0.026921\n",
            "Train Epoch: 0 [110080/163841 (67%)]\tLoss: 0.341759\n",
            "Train Epoch: 0 [110720/163841 (68%)]\tLoss: 0.044801\n",
            "Train Epoch: 0 [111360/163841 (68%)]\tLoss: 0.031927\n",
            "Train Epoch: 0 [112000/163841 (68%)]\tLoss: 0.055126\n",
            "Train Epoch: 0 [112640/163841 (69%)]\tLoss: 0.049708\n",
            "Train Epoch: 0 [113280/163841 (69%)]\tLoss: 0.170247\n",
            "Train Epoch: 0 [113920/163841 (70%)]\tLoss: 0.055829\n",
            "Train Epoch: 0 [114560/163841 (70%)]\tLoss: 0.102682\n",
            "Train Epoch: 0 [115200/163841 (70%)]\tLoss: 0.022389\n",
            "Train Epoch: 0 [115840/163841 (71%)]\tLoss: 0.058156\n",
            "Train Epoch: 0 [116480/163841 (71%)]\tLoss: 0.012763\n",
            "Train Epoch: 0 [117120/163841 (71%)]\tLoss: 0.069938\n",
            "Train Epoch: 0 [117760/163841 (72%)]\tLoss: 0.030166\n",
            "Train Epoch: 0 [118400/163841 (72%)]\tLoss: 0.066691\n",
            "Train Epoch: 0 [119040/163841 (73%)]\tLoss: 0.042431\n",
            "Train Epoch: 0 [119680/163841 (73%)]\tLoss: 0.069722\n",
            "Train Epoch: 0 [120320/163841 (73%)]\tLoss: 0.035333\n",
            "Train Epoch: 0 [120960/163841 (74%)]\tLoss: 0.076186\n",
            "Train Epoch: 0 [121600/163841 (74%)]\tLoss: 0.025958\n",
            "Train Epoch: 0 [122240/163841 (75%)]\tLoss: 0.021993\n",
            "Train Epoch: 0 [122880/163841 (75%)]\tLoss: 0.003243\n",
            "Train Epoch: 0 [123520/163841 (75%)]\tLoss: 0.010810\n",
            "Train Epoch: 0 [124160/163841 (76%)]\tLoss: 0.109269\n",
            "Train Epoch: 0 [124800/163841 (76%)]\tLoss: 0.139649\n",
            "Train Epoch: 0 [125440/163841 (77%)]\tLoss: 0.022923\n",
            "Train Epoch: 0 [126080/163841 (77%)]\tLoss: 0.026347\n",
            "Train Epoch: 0 [126720/163841 (77%)]\tLoss: 0.177354\n",
            "Train Epoch: 0 [127360/163841 (78%)]\tLoss: 0.015942\n",
            "Train Epoch: 0 [128000/163841 (78%)]\tLoss: 0.063887\n",
            "Train Epoch: 0 [128640/163841 (78%)]\tLoss: 0.039179\n",
            "Train Epoch: 0 [129280/163841 (79%)]\tLoss: 0.041729\n",
            "Train Epoch: 0 [129920/163841 (79%)]\tLoss: 0.098057\n",
            "Train Epoch: 0 [130560/163841 (80%)]\tLoss: 0.046045\n",
            "Train Epoch: 0 [131200/163841 (80%)]\tLoss: 0.167519\n",
            "Train Epoch: 0 [131840/163841 (80%)]\tLoss: 0.039102\n",
            "Train Epoch: 0 [132480/163841 (81%)]\tLoss: 0.205696\n",
            "Train Epoch: 0 [133120/163841 (81%)]\tLoss: 0.107446\n",
            "Train Epoch: 0 [133760/163841 (82%)]\tLoss: 0.215980\n",
            "Train Epoch: 0 [134400/163841 (82%)]\tLoss: 0.020153\n",
            "Train Epoch: 0 [135040/163841 (82%)]\tLoss: 0.033585\n",
            "Train Epoch: 0 [135680/163841 (83%)]\tLoss: 0.017593\n",
            "Train Epoch: 0 [136320/163841 (83%)]\tLoss: 0.046898\n",
            "Train Epoch: 0 [136960/163841 (84%)]\tLoss: 0.205704\n",
            "Train Epoch: 0 [137600/163841 (84%)]\tLoss: 0.101968\n",
            "Train Epoch: 0 [138240/163841 (84%)]\tLoss: 0.028849\n",
            "Train Epoch: 0 [138880/163841 (85%)]\tLoss: 0.016307\n",
            "Train Epoch: 0 [139520/163841 (85%)]\tLoss: 0.007058\n",
            "Train Epoch: 0 [140160/163841 (86%)]\tLoss: 0.042315\n",
            "Train Epoch: 0 [140800/163841 (86%)]\tLoss: 0.015404\n",
            "Train Epoch: 0 [141440/163841 (86%)]\tLoss: 0.277135\n",
            "Train Epoch: 0 [142080/163841 (87%)]\tLoss: 0.261343\n",
            "Train Epoch: 0 [142720/163841 (87%)]\tLoss: 0.017172\n",
            "Train Epoch: 0 [143360/163841 (87%)]\tLoss: 0.020651\n",
            "Train Epoch: 0 [144000/163841 (88%)]\tLoss: 0.021328\n",
            "Train Epoch: 0 [144640/163841 (88%)]\tLoss: 0.005419\n",
            "Train Epoch: 0 [145280/163841 (89%)]\tLoss: 0.193773\n",
            "Train Epoch: 0 [145920/163841 (89%)]\tLoss: 0.029718\n",
            "Train Epoch: 0 [146560/163841 (89%)]\tLoss: 0.184223\n",
            "Train Epoch: 0 [147200/163841 (90%)]\tLoss: 0.038769\n",
            "Train Epoch: 0 [147840/163841 (90%)]\tLoss: 0.008954\n",
            "Train Epoch: 0 [148480/163841 (91%)]\tLoss: 0.068106\n",
            "Train Epoch: 0 [149120/163841 (91%)]\tLoss: 0.077925\n",
            "Train Epoch: 0 [149760/163841 (91%)]\tLoss: 0.046003\n",
            "Train Epoch: 0 [150400/163841 (92%)]\tLoss: 0.067429\n",
            "Train Epoch: 0 [151040/163841 (92%)]\tLoss: 0.006638\n",
            "Train Epoch: 0 [151680/163841 (93%)]\tLoss: 0.098629\n",
            "Train Epoch: 0 [152320/163841 (93%)]\tLoss: 0.024598\n",
            "Train Epoch: 0 [152960/163841 (93%)]\tLoss: 0.018131\n",
            "Train Epoch: 0 [153600/163841 (94%)]\tLoss: 0.088781\n",
            "Train Epoch: 0 [154240/163841 (94%)]\tLoss: 0.005986\n",
            "Train Epoch: 0 [154880/163841 (94%)]\tLoss: 0.129130\n",
            "Train Epoch: 0 [155520/163841 (95%)]\tLoss: 0.015938\n",
            "Train Epoch: 0 [156160/163841 (95%)]\tLoss: 0.020786\n",
            "Train Epoch: 0 [156800/163841 (96%)]\tLoss: 0.034725\n",
            "Train Epoch: 0 [157440/163841 (96%)]\tLoss: 0.022666\n",
            "Train Epoch: 0 [158080/163841 (96%)]\tLoss: 0.012486\n",
            "Train Epoch: 0 [158720/163841 (97%)]\tLoss: 0.014397\n",
            "Train Epoch: 0 [159360/163841 (97%)]\tLoss: 0.110349\n",
            "Train Epoch: 0 [160000/163841 (98%)]\tLoss: 0.061959\n",
            "Train Epoch: 0 [160640/163841 (98%)]\tLoss: 0.111105\n",
            "Train Epoch: 0 [161280/163841 (98%)]\tLoss: 0.672888\n",
            "Train Epoch: 0 [161920/163841 (99%)]\tLoss: 0.155397\n",
            "Train Epoch: 0 [162560/163841 (99%)]\tLoss: 0.020672\n",
            "Train Epoch: 0 [163200/163841 (100%)]\tLoss: 0.007729\n",
            "Train Epoch: 0 [2560/163841 (100%)]\tLoss: 2.079465\n",
            "\n",
            "Test set: Average loss: 0.0084, Accuracy: 141217/163841 (86%)\n",
            "\n",
            "Train Epoch: 1 [0/163841 (0%)]\tLoss: 0.272523\n",
            "Train Epoch: 1 [640/163841 (0%)]\tLoss: 0.091303\n",
            "Train Epoch: 1 [1280/163841 (1%)]\tLoss: 0.081847\n",
            "Train Epoch: 1 [1920/163841 (1%)]\tLoss: 0.069639\n",
            "Train Epoch: 1 [2560/163841 (2%)]\tLoss: 0.107536\n",
            "Train Epoch: 1 [3200/163841 (2%)]\tLoss: 0.051395\n",
            "Train Epoch: 1 [3840/163841 (2%)]\tLoss: 0.012753\n",
            "Train Epoch: 1 [4480/163841 (3%)]\tLoss: 0.052519\n",
            "Train Epoch: 1 [5120/163841 (3%)]\tLoss: 0.228445\n",
            "Train Epoch: 1 [5760/163841 (4%)]\tLoss: 0.082010\n",
            "Train Epoch: 1 [6400/163841 (4%)]\tLoss: 0.076345\n",
            "Train Epoch: 1 [7040/163841 (4%)]\tLoss: 0.095391\n",
            "Train Epoch: 1 [7680/163841 (5%)]\tLoss: 0.116221\n",
            "Train Epoch: 1 [8320/163841 (5%)]\tLoss: 0.005050\n",
            "Train Epoch: 1 [8960/163841 (5%)]\tLoss: 0.134033\n",
            "Train Epoch: 1 [9600/163841 (6%)]\tLoss: 0.057280\n",
            "Train Epoch: 1 [10240/163841 (6%)]\tLoss: 0.088205\n",
            "Train Epoch: 1 [10880/163841 (7%)]\tLoss: 0.032922\n",
            "Train Epoch: 1 [11520/163841 (7%)]\tLoss: 0.015916\n",
            "Train Epoch: 1 [12160/163841 (7%)]\tLoss: 0.130998\n",
            "Train Epoch: 1 [12800/163841 (8%)]\tLoss: 0.006296\n",
            "Train Epoch: 1 [13440/163841 (8%)]\tLoss: 0.046913\n",
            "Train Epoch: 1 [14080/163841 (9%)]\tLoss: 0.209512\n",
            "Train Epoch: 1 [14720/163841 (9%)]\tLoss: 0.103523\n",
            "Train Epoch: 1 [15360/163841 (9%)]\tLoss: 0.011878\n",
            "Train Epoch: 1 [16000/163841 (10%)]\tLoss: 0.008508\n",
            "Train Epoch: 1 [16640/163841 (10%)]\tLoss: 0.004866\n",
            "Train Epoch: 1 [17280/163841 (11%)]\tLoss: 0.017515\n",
            "Train Epoch: 1 [17920/163841 (11%)]\tLoss: 0.024558\n",
            "Train Epoch: 1 [18560/163841 (11%)]\tLoss: 0.014642\n",
            "Train Epoch: 1 [19200/163841 (12%)]\tLoss: 0.009774\n",
            "Train Epoch: 1 [19840/163841 (12%)]\tLoss: 0.018855\n",
            "Train Epoch: 1 [20480/163841 (12%)]\tLoss: 0.003670\n",
            "Train Epoch: 1 [21120/163841 (13%)]\tLoss: 0.004085\n",
            "Train Epoch: 1 [21760/163841 (13%)]\tLoss: 0.008889\n",
            "Train Epoch: 1 [22400/163841 (14%)]\tLoss: 0.005194\n",
            "Train Epoch: 1 [23040/163841 (14%)]\tLoss: 0.000181\n",
            "Train Epoch: 1 [23680/163841 (14%)]\tLoss: 0.002896\n",
            "Train Epoch: 1 [24320/163841 (15%)]\tLoss: 0.046442\n",
            "Train Epoch: 1 [24960/163841 (15%)]\tLoss: 0.034847\n",
            "Train Epoch: 1 [25600/163841 (16%)]\tLoss: 0.005898\n",
            "Train Epoch: 1 [26240/163841 (16%)]\tLoss: 0.004279\n",
            "Train Epoch: 1 [26880/163841 (16%)]\tLoss: 0.030482\n",
            "Train Epoch: 1 [27520/163841 (17%)]\tLoss: 0.028449\n",
            "Train Epoch: 1 [28160/163841 (17%)]\tLoss: 0.007182\n",
            "Train Epoch: 1 [28800/163841 (18%)]\tLoss: 0.073692\n",
            "Train Epoch: 1 [29440/163841 (18%)]\tLoss: 0.175600\n",
            "Train Epoch: 1 [30080/163841 (18%)]\tLoss: 0.029407\n",
            "Train Epoch: 1 [30720/163841 (19%)]\tLoss: 0.021518\n",
            "Train Epoch: 1 [31360/163841 (19%)]\tLoss: 0.038394\n",
            "Train Epoch: 1 [32000/163841 (20%)]\tLoss: 0.001856\n",
            "Train Epoch: 1 [32640/163841 (20%)]\tLoss: 0.068585\n",
            "Train Epoch: 1 [33280/163841 (20%)]\tLoss: 0.007289\n",
            "Train Epoch: 1 [33920/163841 (21%)]\tLoss: 0.017354\n",
            "Train Epoch: 1 [34560/163841 (21%)]\tLoss: 0.002272\n",
            "Train Epoch: 1 [35200/163841 (21%)]\tLoss: 0.005602\n",
            "Train Epoch: 1 [35840/163841 (22%)]\tLoss: 0.020015\n",
            "Train Epoch: 1 [36480/163841 (22%)]\tLoss: 0.014260\n",
            "Train Epoch: 1 [37120/163841 (23%)]\tLoss: 0.004896\n",
            "Train Epoch: 1 [37760/163841 (23%)]\tLoss: 0.143855\n",
            "Train Epoch: 1 [38400/163841 (23%)]\tLoss: 0.018825\n",
            "Train Epoch: 1 [39040/163841 (24%)]\tLoss: 0.005046\n",
            "Train Epoch: 1 [39680/163841 (24%)]\tLoss: 0.015933\n",
            "Train Epoch: 1 [40320/163841 (25%)]\tLoss: 0.015320\n",
            "Train Epoch: 1 [40960/163841 (25%)]\tLoss: 0.006944\n",
            "Train Epoch: 1 [41600/163841 (25%)]\tLoss: 0.009747\n",
            "Train Epoch: 1 [42240/163841 (26%)]\tLoss: 0.018541\n",
            "Train Epoch: 1 [42880/163841 (26%)]\tLoss: 0.203326\n",
            "Train Epoch: 1 [43520/163841 (27%)]\tLoss: 0.057858\n",
            "Train Epoch: 1 [44160/163841 (27%)]\tLoss: 0.005703\n",
            "Train Epoch: 1 [44800/163841 (27%)]\tLoss: 0.025772\n",
            "Train Epoch: 1 [45440/163841 (28%)]\tLoss: 0.007067\n",
            "Train Epoch: 1 [46080/163841 (28%)]\tLoss: 0.024046\n",
            "Train Epoch: 1 [46720/163841 (29%)]\tLoss: 0.012101\n",
            "Train Epoch: 1 [47360/163841 (29%)]\tLoss: 0.002252\n",
            "Train Epoch: 1 [48000/163841 (29%)]\tLoss: 0.004003\n",
            "Train Epoch: 1 [48640/163841 (30%)]\tLoss: 0.025881\n",
            "Train Epoch: 1 [49280/163841 (30%)]\tLoss: 0.009168\n",
            "Train Epoch: 1 [49920/163841 (30%)]\tLoss: 0.008267\n",
            "Train Epoch: 1 [50560/163841 (31%)]\tLoss: 0.030663\n",
            "Train Epoch: 1 [51200/163841 (31%)]\tLoss: 0.001352\n",
            "Train Epoch: 1 [51840/163841 (32%)]\tLoss: 0.092243\n",
            "Train Epoch: 1 [52480/163841 (32%)]\tLoss: 0.029923\n",
            "Train Epoch: 1 [53120/163841 (32%)]\tLoss: 0.002182\n",
            "Train Epoch: 1 [53760/163841 (33%)]\tLoss: 0.004710\n",
            "Train Epoch: 1 [54400/163841 (33%)]\tLoss: 0.008691\n",
            "Train Epoch: 1 [55040/163841 (34%)]\tLoss: 0.095343\n",
            "Train Epoch: 1 [55680/163841 (34%)]\tLoss: 0.157603\n",
            "Train Epoch: 1 [56320/163841 (34%)]\tLoss: 0.044188\n",
            "Train Epoch: 1 [56960/163841 (35%)]\tLoss: 0.018142\n",
            "Train Epoch: 1 [57600/163841 (35%)]\tLoss: 0.130098\n",
            "Train Epoch: 1 [58240/163841 (36%)]\tLoss: 0.135290\n",
            "Train Epoch: 1 [58880/163841 (36%)]\tLoss: 0.035006\n",
            "Train Epoch: 1 [59520/163841 (36%)]\tLoss: 0.007111\n",
            "Train Epoch: 1 [60160/163841 (37%)]\tLoss: 0.020794\n",
            "Train Epoch: 1 [60800/163841 (37%)]\tLoss: 0.242000\n",
            "Train Epoch: 1 [61440/163841 (37%)]\tLoss: 0.131400\n",
            "Train Epoch: 1 [62080/163841 (38%)]\tLoss: 0.167994\n",
            "Train Epoch: 1 [62720/163841 (38%)]\tLoss: 0.164882\n",
            "Train Epoch: 1 [63360/163841 (39%)]\tLoss: 0.037306\n",
            "Train Epoch: 1 [64000/163841 (39%)]\tLoss: 0.016046\n",
            "Train Epoch: 1 [64640/163841 (39%)]\tLoss: 0.012167\n",
            "Train Epoch: 1 [65280/163841 (40%)]\tLoss: 0.028569\n",
            "Train Epoch: 1 [65920/163841 (40%)]\tLoss: 0.108029\n",
            "Train Epoch: 1 [66560/163841 (41%)]\tLoss: 0.090260\n",
            "Train Epoch: 1 [67200/163841 (41%)]\tLoss: 0.012882\n",
            "Train Epoch: 1 [67840/163841 (41%)]\tLoss: 0.008143\n",
            "Train Epoch: 1 [68480/163841 (42%)]\tLoss: 0.029741\n",
            "Train Epoch: 1 [69120/163841 (42%)]\tLoss: 0.095131\n",
            "Train Epoch: 1 [69760/163841 (43%)]\tLoss: 0.010733\n",
            "Train Epoch: 1 [70400/163841 (43%)]\tLoss: 0.014052\n",
            "Train Epoch: 1 [71040/163841 (43%)]\tLoss: 0.008030\n",
            "Train Epoch: 1 [71680/163841 (44%)]\tLoss: 0.015954\n",
            "Train Epoch: 1 [72320/163841 (44%)]\tLoss: 0.025171\n",
            "Train Epoch: 1 [72960/163841 (45%)]\tLoss: 0.017581\n",
            "Train Epoch: 1 [73600/163841 (45%)]\tLoss: 0.018910\n",
            "Train Epoch: 1 [74240/163841 (45%)]\tLoss: 0.004837\n",
            "Train Epoch: 1 [74880/163841 (46%)]\tLoss: 0.006503\n",
            "Train Epoch: 1 [75520/163841 (46%)]\tLoss: 0.010549\n",
            "Train Epoch: 1 [76160/163841 (46%)]\tLoss: 0.013046\n",
            "Train Epoch: 1 [76800/163841 (47%)]\tLoss: 0.004274\n",
            "Train Epoch: 1 [77440/163841 (47%)]\tLoss: 0.001486\n",
            "Train Epoch: 1 [78080/163841 (48%)]\tLoss: 0.024885\n",
            "Train Epoch: 1 [78720/163841 (48%)]\tLoss: 0.050809\n",
            "Train Epoch: 1 [79360/163841 (48%)]\tLoss: 0.005737\n",
            "Train Epoch: 1 [80000/163841 (49%)]\tLoss: 0.002098\n",
            "Train Epoch: 1 [80640/163841 (49%)]\tLoss: 0.025567\n",
            "Train Epoch: 1 [81280/163841 (50%)]\tLoss: 0.004614\n",
            "Train Epoch: 1 [81920/163841 (50%)]\tLoss: 0.001546\n",
            "Train Epoch: 1 [82560/163841 (50%)]\tLoss: 0.014195\n",
            "Train Epoch: 1 [83200/163841 (51%)]\tLoss: 0.022462\n",
            "Train Epoch: 1 [83840/163841 (51%)]\tLoss: 0.003556\n",
            "Train Epoch: 1 [84480/163841 (52%)]\tLoss: 0.000450\n",
            "Train Epoch: 1 [85120/163841 (52%)]\tLoss: 0.117410\n",
            "Train Epoch: 1 [85760/163841 (52%)]\tLoss: 0.098523\n",
            "Train Epoch: 1 [86400/163841 (53%)]\tLoss: 0.011787\n",
            "Train Epoch: 1 [87040/163841 (53%)]\tLoss: 0.044316\n",
            "Train Epoch: 1 [87680/163841 (53%)]\tLoss: 0.019702\n",
            "Train Epoch: 1 [88320/163841 (54%)]\tLoss: 0.006304\n",
            "Train Epoch: 1 [88960/163841 (54%)]\tLoss: 0.018045\n",
            "Train Epoch: 1 [89600/163841 (55%)]\tLoss: 0.041647\n",
            "Train Epoch: 1 [90240/163841 (55%)]\tLoss: 0.157757\n",
            "Train Epoch: 1 [90880/163841 (55%)]\tLoss: 0.120845\n",
            "Train Epoch: 1 [91520/163841 (56%)]\tLoss: 0.091393\n",
            "Train Epoch: 1 [92160/163841 (56%)]\tLoss: 0.151082\n",
            "Train Epoch: 1 [92800/163841 (57%)]\tLoss: 0.067743\n",
            "Train Epoch: 1 [93440/163841 (57%)]\tLoss: 0.026388\n",
            "Train Epoch: 1 [94080/163841 (57%)]\tLoss: 0.028949\n",
            "Train Epoch: 1 [94720/163841 (58%)]\tLoss: 0.048746\n",
            "Train Epoch: 1 [95360/163841 (58%)]\tLoss: 0.076310\n",
            "Train Epoch: 1 [96000/163841 (59%)]\tLoss: 0.007758\n",
            "Train Epoch: 1 [96640/163841 (59%)]\tLoss: 0.015556\n",
            "Train Epoch: 1 [97280/163841 (59%)]\tLoss: 0.059972\n",
            "Train Epoch: 1 [97920/163841 (60%)]\tLoss: 0.023109\n",
            "Train Epoch: 1 [98560/163841 (60%)]\tLoss: 0.036890\n",
            "Train Epoch: 1 [99200/163841 (61%)]\tLoss: 0.077713\n",
            "Train Epoch: 1 [99840/163841 (61%)]\tLoss: 0.015496\n",
            "Train Epoch: 1 [100480/163841 (61%)]\tLoss: 0.004740\n",
            "Train Epoch: 1 [101120/163841 (62%)]\tLoss: 0.016544\n",
            "Train Epoch: 1 [101760/163841 (62%)]\tLoss: 0.018926\n",
            "Train Epoch: 1 [102400/163841 (62%)]\tLoss: 0.005174\n",
            "Train Epoch: 1 [103040/163841 (63%)]\tLoss: 0.004167\n",
            "Train Epoch: 1 [103680/163841 (63%)]\tLoss: 0.029582\n",
            "Train Epoch: 1 [104320/163841 (64%)]\tLoss: 0.006320\n",
            "Train Epoch: 1 [104960/163841 (64%)]\tLoss: 0.007258\n",
            "Train Epoch: 1 [105600/163841 (64%)]\tLoss: 0.008599\n",
            "Train Epoch: 1 [106240/163841 (65%)]\tLoss: 0.226110\n",
            "Train Epoch: 1 [106880/163841 (65%)]\tLoss: 0.018213\n",
            "Train Epoch: 1 [107520/163841 (66%)]\tLoss: 0.120407\n",
            "Train Epoch: 1 [108160/163841 (66%)]\tLoss: 0.000676\n",
            "Train Epoch: 1 [108800/163841 (66%)]\tLoss: 0.017407\n",
            "Train Epoch: 1 [109440/163841 (67%)]\tLoss: 0.031867\n",
            "Train Epoch: 1 [110080/163841 (67%)]\tLoss: 0.000634\n",
            "Train Epoch: 1 [110720/163841 (68%)]\tLoss: 0.012875\n",
            "Train Epoch: 1 [111360/163841 (68%)]\tLoss: 0.034682\n",
            "Train Epoch: 1 [112000/163841 (68%)]\tLoss: 0.012034\n",
            "Train Epoch: 1 [112640/163841 (69%)]\tLoss: 0.012475\n",
            "Train Epoch: 1 [113280/163841 (69%)]\tLoss: 0.041963\n",
            "Train Epoch: 1 [113920/163841 (70%)]\tLoss: 0.021801\n",
            "Train Epoch: 1 [114560/163841 (70%)]\tLoss: 0.003185\n",
            "Train Epoch: 1 [115200/163841 (70%)]\tLoss: 0.008597\n",
            "Train Epoch: 1 [115840/163841 (71%)]\tLoss: 0.007707\n",
            "Train Epoch: 1 [116480/163841 (71%)]\tLoss: 0.234253\n",
            "Train Epoch: 1 [117120/163841 (71%)]\tLoss: 0.037976\n",
            "Train Epoch: 1 [117760/163841 (72%)]\tLoss: 0.034196\n",
            "Train Epoch: 1 [118400/163841 (72%)]\tLoss: 0.015410\n",
            "Train Epoch: 1 [119040/163841 (73%)]\tLoss: 0.000582\n",
            "Train Epoch: 1 [119680/163841 (73%)]\tLoss: 0.003668\n",
            "Train Epoch: 1 [120320/163841 (73%)]\tLoss: 0.002150\n",
            "Train Epoch: 1 [120960/163841 (74%)]\tLoss: 0.001261\n",
            "Train Epoch: 1 [121600/163841 (74%)]\tLoss: 0.002026\n",
            "Train Epoch: 1 [122240/163841 (75%)]\tLoss: 0.008410\n",
            "Train Epoch: 1 [122880/163841 (75%)]\tLoss: 0.112344\n",
            "Train Epoch: 1 [123520/163841 (75%)]\tLoss: 0.013311\n",
            "Train Epoch: 1 [124160/163841 (76%)]\tLoss: 0.005850\n",
            "Train Epoch: 1 [124800/163841 (76%)]\tLoss: 0.017016\n",
            "Train Epoch: 1 [125440/163841 (77%)]\tLoss: 0.000369\n",
            "Train Epoch: 1 [126080/163841 (77%)]\tLoss: 0.142572\n",
            "Train Epoch: 1 [126720/163841 (77%)]\tLoss: 0.001541\n",
            "Train Epoch: 1 [127360/163841 (78%)]\tLoss: 0.000805\n",
            "Train Epoch: 1 [128000/163841 (78%)]\tLoss: 0.118091\n",
            "Train Epoch: 1 [128640/163841 (78%)]\tLoss: 0.003617\n",
            "Train Epoch: 1 [129280/163841 (79%)]\tLoss: 0.016454\n",
            "Train Epoch: 1 [129920/163841 (79%)]\tLoss: 0.003086\n",
            "Train Epoch: 1 [130560/163841 (80%)]\tLoss: 0.112864\n",
            "Train Epoch: 1 [131200/163841 (80%)]\tLoss: 0.071463\n",
            "Train Epoch: 1 [131840/163841 (80%)]\tLoss: 0.008977\n",
            "Train Epoch: 1 [132480/163841 (81%)]\tLoss: 0.030638\n",
            "Train Epoch: 1 [133120/163841 (81%)]\tLoss: 0.031109\n",
            "Train Epoch: 1 [133760/163841 (82%)]\tLoss: 0.011420\n",
            "Train Epoch: 1 [134400/163841 (82%)]\tLoss: 0.026564\n",
            "Train Epoch: 1 [135040/163841 (82%)]\tLoss: 0.000948\n",
            "Train Epoch: 1 [135680/163841 (83%)]\tLoss: 0.004509\n",
            "Train Epoch: 1 [136320/163841 (83%)]\tLoss: 0.036337\n",
            "Train Epoch: 1 [136960/163841 (84%)]\tLoss: 0.002497\n",
            "Train Epoch: 1 [137600/163841 (84%)]\tLoss: 0.022930\n",
            "Train Epoch: 1 [138240/163841 (84%)]\tLoss: 0.071568\n",
            "Train Epoch: 1 [138880/163841 (85%)]\tLoss: 0.025152\n",
            "Train Epoch: 1 [139520/163841 (85%)]\tLoss: 0.083751\n",
            "Train Epoch: 1 [140160/163841 (86%)]\tLoss: 0.044961\n",
            "Train Epoch: 1 [140800/163841 (86%)]\tLoss: 0.020168\n",
            "Train Epoch: 1 [141440/163841 (86%)]\tLoss: 0.126672\n",
            "Train Epoch: 1 [142080/163841 (87%)]\tLoss: 0.064532\n",
            "Train Epoch: 1 [142720/163841 (87%)]\tLoss: 0.007205\n",
            "Train Epoch: 1 [143360/163841 (87%)]\tLoss: 0.006699\n",
            "Train Epoch: 1 [144000/163841 (88%)]\tLoss: 0.190833\n",
            "Train Epoch: 1 [144640/163841 (88%)]\tLoss: 0.103278\n",
            "Train Epoch: 1 [145280/163841 (89%)]\tLoss: 0.003203\n",
            "Train Epoch: 1 [145920/163841 (89%)]\tLoss: 0.018062\n",
            "Train Epoch: 1 [146560/163841 (89%)]\tLoss: 0.011969\n",
            "Train Epoch: 1 [147200/163841 (90%)]\tLoss: 0.061979\n",
            "Train Epoch: 1 [147840/163841 (90%)]\tLoss: 0.011325\n",
            "Train Epoch: 1 [148480/163841 (91%)]\tLoss: 0.025477\n",
            "Train Epoch: 1 [149120/163841 (91%)]\tLoss: 0.030132\n",
            "Train Epoch: 1 [149760/163841 (91%)]\tLoss: 0.094879\n",
            "Train Epoch: 1 [150400/163841 (92%)]\tLoss: 0.027198\n",
            "Train Epoch: 1 [151040/163841 (92%)]\tLoss: 0.004856\n",
            "Train Epoch: 1 [151680/163841 (93%)]\tLoss: 0.006531\n",
            "Train Epoch: 1 [152320/163841 (93%)]\tLoss: 0.053148\n",
            "Train Epoch: 1 [152960/163841 (93%)]\tLoss: 0.036426\n",
            "Train Epoch: 1 [153600/163841 (94%)]\tLoss: 0.047667\n",
            "Train Epoch: 1 [154240/163841 (94%)]\tLoss: 0.076924\n",
            "Train Epoch: 1 [154880/163841 (94%)]\tLoss: 0.098941\n",
            "Train Epoch: 1 [155520/163841 (95%)]\tLoss: 0.093102\n",
            "Train Epoch: 1 [156160/163841 (95%)]\tLoss: 0.024757\n",
            "Train Epoch: 1 [156800/163841 (96%)]\tLoss: 0.119132\n",
            "Train Epoch: 1 [157440/163841 (96%)]\tLoss: 0.112470\n",
            "Train Epoch: 1 [158080/163841 (96%)]\tLoss: 0.073331\n",
            "Train Epoch: 1 [158720/163841 (97%)]\tLoss: 0.023052\n",
            "Train Epoch: 1 [159360/163841 (97%)]\tLoss: 0.072204\n",
            "Train Epoch: 1 [160000/163841 (98%)]\tLoss: 0.040952\n",
            "Train Epoch: 1 [160640/163841 (98%)]\tLoss: 0.025817\n",
            "Train Epoch: 1 [161280/163841 (98%)]\tLoss: 0.036592\n",
            "Train Epoch: 1 [161920/163841 (99%)]\tLoss: 0.015576\n",
            "Train Epoch: 1 [162560/163841 (99%)]\tLoss: 0.059260\n",
            "Train Epoch: 1 [163200/163841 (100%)]\tLoss: 0.024110\n",
            "Train Epoch: 1 [2560/163841 (100%)]\tLoss: 0.617958\n",
            "\n",
            "Test set: Average loss: 0.0003, Accuracy: 162807/163841 (99%)\n",
            "\n",
            "Train Epoch: 2 [0/163841 (0%)]\tLoss: 0.008264\n",
            "Train Epoch: 2 [640/163841 (0%)]\tLoss: 0.020974\n",
            "Train Epoch: 2 [1280/163841 (1%)]\tLoss: 0.061842\n",
            "Train Epoch: 2 [1920/163841 (1%)]\tLoss: 0.093150\n",
            "Train Epoch: 2 [2560/163841 (2%)]\tLoss: 0.065742\n",
            "Train Epoch: 2 [3200/163841 (2%)]\tLoss: 0.192118\n",
            "Train Epoch: 2 [3840/163841 (2%)]\tLoss: 0.017320\n",
            "Train Epoch: 2 [4480/163841 (3%)]\tLoss: 0.052071\n",
            "Train Epoch: 2 [5120/163841 (3%)]\tLoss: 0.008651\n",
            "Train Epoch: 2 [5760/163841 (4%)]\tLoss: 0.065549\n",
            "Train Epoch: 2 [6400/163841 (4%)]\tLoss: 0.087704\n",
            "Train Epoch: 2 [7040/163841 (4%)]\tLoss: 0.046785\n",
            "Train Epoch: 2 [7680/163841 (5%)]\tLoss: 0.179084\n",
            "Train Epoch: 2 [8320/163841 (5%)]\tLoss: 0.014907\n",
            "Train Epoch: 2 [8960/163841 (5%)]\tLoss: 0.001648\n",
            "Train Epoch: 2 [9600/163841 (6%)]\tLoss: 0.135449\n",
            "Train Epoch: 2 [10240/163841 (6%)]\tLoss: 0.004162\n",
            "Train Epoch: 2 [10880/163841 (7%)]\tLoss: 0.008732\n",
            "Train Epoch: 2 [11520/163841 (7%)]\tLoss: 0.006972\n",
            "Train Epoch: 2 [12160/163841 (7%)]\tLoss: 0.002096\n",
            "Train Epoch: 2 [12800/163841 (8%)]\tLoss: 0.017902\n",
            "Train Epoch: 2 [13440/163841 (8%)]\tLoss: 0.034831\n",
            "Train Epoch: 2 [14080/163841 (9%)]\tLoss: 0.003251\n",
            "Train Epoch: 2 [14720/163841 (9%)]\tLoss: 0.002087\n",
            "Train Epoch: 2 [15360/163841 (9%)]\tLoss: 0.014430\n",
            "Train Epoch: 2 [16000/163841 (10%)]\tLoss: 0.008362\n",
            "Train Epoch: 2 [16640/163841 (10%)]\tLoss: 0.013233\n",
            "Train Epoch: 2 [17280/163841 (11%)]\tLoss: 0.007148\n",
            "Train Epoch: 2 [17920/163841 (11%)]\tLoss: 0.028321\n",
            "Train Epoch: 2 [18560/163841 (11%)]\tLoss: 0.118517\n",
            "Train Epoch: 2 [19200/163841 (12%)]\tLoss: 0.077382\n",
            "Train Epoch: 2 [19840/163841 (12%)]\tLoss: 0.139767\n",
            "Train Epoch: 2 [20480/163841 (12%)]\tLoss: 0.004487\n",
            "Train Epoch: 2 [21120/163841 (13%)]\tLoss: 0.032903\n",
            "Train Epoch: 2 [21760/163841 (13%)]\tLoss: 0.012296\n",
            "Train Epoch: 2 [22400/163841 (14%)]\tLoss: 0.005375\n",
            "Train Epoch: 2 [23040/163841 (14%)]\tLoss: 0.083194\n",
            "Train Epoch: 2 [23680/163841 (14%)]\tLoss: 0.005081\n",
            "Train Epoch: 2 [24320/163841 (15%)]\tLoss: 0.061281\n",
            "Train Epoch: 2 [24960/163841 (15%)]\tLoss: 0.005844\n",
            "Train Epoch: 2 [25600/163841 (16%)]\tLoss: 0.043647\n",
            "Train Epoch: 2 [26240/163841 (16%)]\tLoss: 0.011209\n",
            "Train Epoch: 2 [26880/163841 (16%)]\tLoss: 0.003120\n",
            "Train Epoch: 2 [27520/163841 (17%)]\tLoss: 0.007509\n",
            "Train Epoch: 2 [28160/163841 (17%)]\tLoss: 0.023354\n",
            "Train Epoch: 2 [28800/163841 (18%)]\tLoss: 0.022058\n",
            "Train Epoch: 2 [29440/163841 (18%)]\tLoss: 0.104561\n",
            "Train Epoch: 2 [30080/163841 (18%)]\tLoss: 0.100364\n",
            "Train Epoch: 2 [30720/163841 (19%)]\tLoss: 0.045484\n",
            "Train Epoch: 2 [31360/163841 (19%)]\tLoss: 0.011304\n",
            "Train Epoch: 2 [32000/163841 (20%)]\tLoss: 0.032805\n",
            "Train Epoch: 2 [32640/163841 (20%)]\tLoss: 0.001244\n",
            "Train Epoch: 2 [33280/163841 (20%)]\tLoss: 0.003813\n",
            "Train Epoch: 2 [33920/163841 (21%)]\tLoss: 0.014852\n",
            "Train Epoch: 2 [34560/163841 (21%)]\tLoss: 0.006510\n",
            "Train Epoch: 2 [35200/163841 (21%)]\tLoss: 0.000447\n",
            "Train Epoch: 2 [35840/163841 (22%)]\tLoss: 0.009181\n",
            "Train Epoch: 2 [36480/163841 (22%)]\tLoss: 0.001664\n",
            "Train Epoch: 2 [37120/163841 (23%)]\tLoss: 0.000271\n",
            "Train Epoch: 2 [37760/163841 (23%)]\tLoss: 0.001578\n",
            "Train Epoch: 2 [38400/163841 (23%)]\tLoss: 0.000438\n",
            "Train Epoch: 2 [39040/163841 (24%)]\tLoss: 0.000218\n",
            "Train Epoch: 2 [39680/163841 (24%)]\tLoss: 0.000144\n",
            "Train Epoch: 2 [40320/163841 (25%)]\tLoss: 0.001487\n",
            "Train Epoch: 2 [40960/163841 (25%)]\tLoss: 0.017042\n",
            "Train Epoch: 2 [41600/163841 (25%)]\tLoss: 0.001185\n",
            "Train Epoch: 2 [42240/163841 (26%)]\tLoss: 0.001208\n",
            "Train Epoch: 2 [42880/163841 (26%)]\tLoss: 0.001152\n",
            "Train Epoch: 2 [43520/163841 (27%)]\tLoss: 0.001108\n",
            "Train Epoch: 2 [44160/163841 (27%)]\tLoss: 0.002334\n",
            "Train Epoch: 2 [44800/163841 (27%)]\tLoss: 0.001176\n",
            "Train Epoch: 2 [45440/163841 (28%)]\tLoss: 0.010776\n",
            "Train Epoch: 2 [46080/163841 (28%)]\tLoss: 0.131596\n",
            "Train Epoch: 2 [46720/163841 (29%)]\tLoss: 0.216018\n",
            "Train Epoch: 2 [47360/163841 (29%)]\tLoss: 0.030035\n",
            "Train Epoch: 2 [48000/163841 (29%)]\tLoss: 0.006935\n",
            "Train Epoch: 2 [48640/163841 (30%)]\tLoss: 0.066342\n",
            "Train Epoch: 2 [49280/163841 (30%)]\tLoss: 0.019670\n",
            "Train Epoch: 2 [49920/163841 (30%)]\tLoss: 0.066911\n",
            "Train Epoch: 2 [50560/163841 (31%)]\tLoss: 0.036931\n",
            "Train Epoch: 2 [51200/163841 (31%)]\tLoss: 0.055203\n",
            "Train Epoch: 2 [51840/163841 (32%)]\tLoss: 0.005315\n",
            "Train Epoch: 2 [52480/163841 (32%)]\tLoss: 0.054156\n",
            "Train Epoch: 2 [53120/163841 (32%)]\tLoss: 0.005245\n",
            "Train Epoch: 2 [53760/163841 (33%)]\tLoss: 0.000126\n",
            "Train Epoch: 2 [54400/163841 (33%)]\tLoss: 0.004441\n",
            "Train Epoch: 2 [55040/163841 (34%)]\tLoss: 0.002432\n",
            "Train Epoch: 2 [55680/163841 (34%)]\tLoss: 0.000625\n",
            "Train Epoch: 2 [56320/163841 (34%)]\tLoss: 0.002303\n",
            "Train Epoch: 2 [56960/163841 (35%)]\tLoss: 0.000561\n",
            "Train Epoch: 2 [57600/163841 (35%)]\tLoss: 0.014731\n",
            "Train Epoch: 2 [58240/163841 (36%)]\tLoss: 0.022936\n",
            "Train Epoch: 2 [58880/163841 (36%)]\tLoss: 0.053789\n",
            "Train Epoch: 2 [59520/163841 (36%)]\tLoss: 0.000217\n",
            "Train Epoch: 2 [60160/163841 (37%)]\tLoss: 0.013232\n",
            "Train Epoch: 2 [60800/163841 (37%)]\tLoss: 0.012740\n",
            "Train Epoch: 2 [61440/163841 (37%)]\tLoss: 0.000377\n",
            "Train Epoch: 2 [62080/163841 (38%)]\tLoss: 0.048159\n",
            "Train Epoch: 2 [62720/163841 (38%)]\tLoss: 0.000999\n",
            "Train Epoch: 2 [63360/163841 (39%)]\tLoss: 0.021502\n",
            "Train Epoch: 2 [64000/163841 (39%)]\tLoss: 0.088799\n",
            "Train Epoch: 2 [64640/163841 (39%)]\tLoss: 0.002813\n",
            "Train Epoch: 2 [65280/163841 (40%)]\tLoss: 0.107130\n",
            "Train Epoch: 2 [65920/163841 (40%)]\tLoss: 0.008156\n",
            "Train Epoch: 2 [66560/163841 (41%)]\tLoss: 0.005895\n",
            "Train Epoch: 2 [67200/163841 (41%)]\tLoss: 0.016923\n",
            "Train Epoch: 2 [67840/163841 (41%)]\tLoss: 0.001229\n",
            "Train Epoch: 2 [68480/163841 (42%)]\tLoss: 0.158859\n",
            "Train Epoch: 2 [69120/163841 (42%)]\tLoss: 0.020500\n",
            "Train Epoch: 2 [69760/163841 (43%)]\tLoss: 0.028120\n",
            "Train Epoch: 2 [70400/163841 (43%)]\tLoss: 0.004404\n",
            "Train Epoch: 2 [71040/163841 (43%)]\tLoss: 0.009957\n",
            "Train Epoch: 2 [71680/163841 (44%)]\tLoss: 0.090361\n",
            "Train Epoch: 2 [72320/163841 (44%)]\tLoss: 0.066080\n",
            "Train Epoch: 2 [72960/163841 (45%)]\tLoss: 0.035838\n",
            "Train Epoch: 2 [73600/163841 (45%)]\tLoss: 0.037946\n",
            "Train Epoch: 2 [74240/163841 (45%)]\tLoss: 0.005368\n",
            "Train Epoch: 2 [74880/163841 (46%)]\tLoss: 0.001755\n",
            "Train Epoch: 2 [75520/163841 (46%)]\tLoss: 0.010270\n",
            "Train Epoch: 2 [76160/163841 (46%)]\tLoss: 0.003368\n",
            "Train Epoch: 2 [76800/163841 (47%)]\tLoss: 0.055437\n",
            "Train Epoch: 2 [77440/163841 (47%)]\tLoss: 0.028061\n",
            "Train Epoch: 2 [78080/163841 (48%)]\tLoss: 0.076417\n",
            "Train Epoch: 2 [78720/163841 (48%)]\tLoss: 0.012021\n",
            "Train Epoch: 2 [79360/163841 (48%)]\tLoss: 0.007555\n",
            "Train Epoch: 2 [80000/163841 (49%)]\tLoss: 0.014770\n",
            "Train Epoch: 2 [80640/163841 (49%)]\tLoss: 0.009666\n",
            "Train Epoch: 2 [81280/163841 (50%)]\tLoss: 0.005846\n",
            "Train Epoch: 2 [81920/163841 (50%)]\tLoss: 0.010445\n",
            "Train Epoch: 2 [82560/163841 (50%)]\tLoss: 0.166205\n",
            "Train Epoch: 2 [83200/163841 (51%)]\tLoss: 0.009020\n",
            "Train Epoch: 2 [83840/163841 (51%)]\tLoss: 0.128309\n",
            "Train Epoch: 2 [84480/163841 (52%)]\tLoss: 0.015361\n",
            "Train Epoch: 2 [85120/163841 (52%)]\tLoss: 0.021963\n",
            "Train Epoch: 2 [85760/163841 (52%)]\tLoss: 0.011111\n",
            "Train Epoch: 2 [86400/163841 (53%)]\tLoss: 0.019051\n",
            "Train Epoch: 2 [87040/163841 (53%)]\tLoss: 0.032988\n",
            "Train Epoch: 2 [87680/163841 (53%)]\tLoss: 0.031697\n",
            "Train Epoch: 2 [88320/163841 (54%)]\tLoss: 0.022198\n",
            "Train Epoch: 2 [88960/163841 (54%)]\tLoss: 0.000995\n",
            "Train Epoch: 2 [89600/163841 (55%)]\tLoss: 0.074236\n",
            "Train Epoch: 2 [90240/163841 (55%)]\tLoss: 0.002060\n",
            "Train Epoch: 2 [90880/163841 (55%)]\tLoss: 0.078261\n",
            "Train Epoch: 2 [91520/163841 (56%)]\tLoss: 0.000413\n",
            "Train Epoch: 2 [92160/163841 (56%)]\tLoss: 0.078060\n",
            "Train Epoch: 2 [92800/163841 (57%)]\tLoss: 0.002511\n",
            "Train Epoch: 2 [93440/163841 (57%)]\tLoss: 0.001825\n",
            "Train Epoch: 2 [94080/163841 (57%)]\tLoss: 0.025364\n",
            "Train Epoch: 2 [94720/163841 (58%)]\tLoss: 0.003414\n",
            "Train Epoch: 2 [95360/163841 (58%)]\tLoss: 0.013296\n",
            "Train Epoch: 2 [96000/163841 (59%)]\tLoss: 0.000327\n",
            "Train Epoch: 2 [96640/163841 (59%)]\tLoss: 0.007755\n",
            "Train Epoch: 2 [97280/163841 (59%)]\tLoss: 0.003035\n",
            "Train Epoch: 2 [97920/163841 (60%)]\tLoss: 0.000789\n",
            "Train Epoch: 2 [98560/163841 (60%)]\tLoss: 0.005602\n",
            "Train Epoch: 2 [99200/163841 (61%)]\tLoss: 0.006548\n",
            "Train Epoch: 2 [99840/163841 (61%)]\tLoss: 0.011501\n",
            "Train Epoch: 2 [100480/163841 (61%)]\tLoss: 0.002012\n",
            "Train Epoch: 2 [101120/163841 (62%)]\tLoss: 0.000230\n",
            "Train Epoch: 2 [101760/163841 (62%)]\tLoss: 0.043927\n",
            "Train Epoch: 2 [102400/163841 (62%)]\tLoss: 0.020196\n",
            "Train Epoch: 2 [103040/163841 (63%)]\tLoss: 0.007067\n",
            "Train Epoch: 2 [103680/163841 (63%)]\tLoss: 0.003332\n",
            "Train Epoch: 2 [104320/163841 (64%)]\tLoss: 0.007463\n",
            "Train Epoch: 2 [104960/163841 (64%)]\tLoss: 0.003714\n",
            "Train Epoch: 2 [105600/163841 (64%)]\tLoss: 0.039077\n",
            "Train Epoch: 2 [106240/163841 (65%)]\tLoss: 0.004341\n",
            "Train Epoch: 2 [106880/163841 (65%)]\tLoss: 0.000933\n",
            "Train Epoch: 2 [107520/163841 (66%)]\tLoss: 0.019498\n",
            "Train Epoch: 2 [108160/163841 (66%)]\tLoss: 0.000554\n",
            "Train Epoch: 2 [108800/163841 (66%)]\tLoss: 0.000663\n",
            "Train Epoch: 2 [109440/163841 (67%)]\tLoss: 0.001260\n",
            "Train Epoch: 2 [110080/163841 (67%)]\tLoss: 0.000817\n",
            "Train Epoch: 2 [110720/163841 (68%)]\tLoss: 0.001645\n",
            "Train Epoch: 2 [111360/163841 (68%)]\tLoss: 0.004097\n",
            "Train Epoch: 2 [112000/163841 (68%)]\tLoss: 0.002133\n",
            "Train Epoch: 2 [112640/163841 (69%)]\tLoss: 0.000484\n",
            "Train Epoch: 2 [113280/163841 (69%)]\tLoss: 0.002483\n",
            "Train Epoch: 2 [113920/163841 (70%)]\tLoss: 0.000512\n",
            "Train Epoch: 2 [114560/163841 (70%)]\tLoss: 0.000494\n",
            "Train Epoch: 2 [115200/163841 (70%)]\tLoss: 0.000499\n",
            "Train Epoch: 2 [115840/163841 (71%)]\tLoss: 0.009600\n",
            "Train Epoch: 2 [116480/163841 (71%)]\tLoss: 0.007481\n",
            "Train Epoch: 2 [117120/163841 (71%)]\tLoss: 0.013150\n",
            "Train Epoch: 2 [117760/163841 (72%)]\tLoss: 0.016889\n",
            "Train Epoch: 2 [118400/163841 (72%)]\tLoss: 0.003438\n",
            "Train Epoch: 2 [119040/163841 (73%)]\tLoss: 0.000405\n",
            "Train Epoch: 2 [119680/163841 (73%)]\tLoss: 0.000799\n",
            "Train Epoch: 2 [120320/163841 (73%)]\tLoss: 0.000507\n",
            "Train Epoch: 2 [120960/163841 (74%)]\tLoss: 0.000625\n",
            "Train Epoch: 2 [121600/163841 (74%)]\tLoss: 0.008123\n",
            "Train Epoch: 2 [122240/163841 (75%)]\tLoss: 0.000393\n",
            "Train Epoch: 2 [122880/163841 (75%)]\tLoss: 0.003492\n",
            "Train Epoch: 2 [123520/163841 (75%)]\tLoss: 0.057845\n",
            "Train Epoch: 2 [124160/163841 (76%)]\tLoss: 0.003042\n",
            "Train Epoch: 2 [124800/163841 (76%)]\tLoss: 0.038057\n",
            "Train Epoch: 2 [125440/163841 (77%)]\tLoss: 0.002324\n",
            "Train Epoch: 2 [126080/163841 (77%)]\tLoss: 0.038538\n",
            "Train Epoch: 2 [126720/163841 (77%)]\tLoss: 0.161918\n",
            "Train Epoch: 2 [127360/163841 (78%)]\tLoss: 0.036502\n",
            "Train Epoch: 2 [128000/163841 (78%)]\tLoss: 0.022317\n",
            "Train Epoch: 2 [128640/163841 (78%)]\tLoss: 0.001433\n",
            "Train Epoch: 2 [129280/163841 (79%)]\tLoss: 0.002315\n",
            "Train Epoch: 2 [129920/163841 (79%)]\tLoss: 0.010698\n",
            "Train Epoch: 2 [130560/163841 (80%)]\tLoss: 0.001287\n",
            "Train Epoch: 2 [131200/163841 (80%)]\tLoss: 0.027706\n",
            "Train Epoch: 2 [131840/163841 (80%)]\tLoss: 0.016120\n",
            "Train Epoch: 2 [132480/163841 (81%)]\tLoss: 0.014162\n",
            "Train Epoch: 2 [133120/163841 (81%)]\tLoss: 0.006306\n",
            "Train Epoch: 2 [133760/163841 (82%)]\tLoss: 0.011409\n",
            "Train Epoch: 2 [134400/163841 (82%)]\tLoss: 0.044869\n",
            "Train Epoch: 2 [135040/163841 (82%)]\tLoss: 0.228413\n",
            "Train Epoch: 2 [135680/163841 (83%)]\tLoss: 0.001466\n",
            "Train Epoch: 2 [136320/163841 (83%)]\tLoss: 0.006087\n",
            "Train Epoch: 2 [136960/163841 (84%)]\tLoss: 0.008400\n",
            "Train Epoch: 2 [137600/163841 (84%)]\tLoss: 0.058689\n",
            "Train Epoch: 2 [138240/163841 (84%)]\tLoss: 0.002949\n",
            "Train Epoch: 2 [138880/163841 (85%)]\tLoss: 0.010236\n",
            "Train Epoch: 2 [139520/163841 (85%)]\tLoss: 0.067605\n",
            "Train Epoch: 2 [140160/163841 (86%)]\tLoss: 0.002996\n",
            "Train Epoch: 2 [140800/163841 (86%)]\tLoss: 0.005091\n",
            "Train Epoch: 2 [141440/163841 (86%)]\tLoss: 0.020940\n",
            "Train Epoch: 2 [142080/163841 (87%)]\tLoss: 0.028045\n",
            "Train Epoch: 2 [142720/163841 (87%)]\tLoss: 0.065434\n",
            "Train Epoch: 2 [143360/163841 (87%)]\tLoss: 0.367091\n",
            "Train Epoch: 2 [144000/163841 (88%)]\tLoss: 0.088455\n",
            "Train Epoch: 2 [144640/163841 (88%)]\tLoss: 0.072351\n",
            "Train Epoch: 2 [145280/163841 (89%)]\tLoss: 0.011318\n",
            "Train Epoch: 2 [145920/163841 (89%)]\tLoss: 0.014352\n",
            "Train Epoch: 2 [146560/163841 (89%)]\tLoss: 0.001110\n",
            "Train Epoch: 2 [147200/163841 (90%)]\tLoss: 0.001227\n",
            "Train Epoch: 2 [147840/163841 (90%)]\tLoss: 0.008039\n",
            "Train Epoch: 2 [148480/163841 (91%)]\tLoss: 0.003313\n",
            "Train Epoch: 2 [149120/163841 (91%)]\tLoss: 0.001989\n",
            "Train Epoch: 2 [149760/163841 (91%)]\tLoss: 0.007502\n",
            "Train Epoch: 2 [150400/163841 (92%)]\tLoss: 0.024185\n",
            "Train Epoch: 2 [151040/163841 (92%)]\tLoss: 0.031478\n",
            "Train Epoch: 2 [151680/163841 (93%)]\tLoss: 0.026206\n",
            "Train Epoch: 2 [152320/163841 (93%)]\tLoss: 0.013398\n",
            "Train Epoch: 2 [152960/163841 (93%)]\tLoss: 0.007633\n",
            "Train Epoch: 2 [153600/163841 (94%)]\tLoss: 0.001274\n",
            "Train Epoch: 2 [154240/163841 (94%)]\tLoss: 0.000803\n",
            "Train Epoch: 2 [154880/163841 (94%)]\tLoss: 0.015608\n",
            "Train Epoch: 2 [155520/163841 (95%)]\tLoss: 0.003607\n",
            "Train Epoch: 2 [156160/163841 (95%)]\tLoss: 0.033513\n",
            "Train Epoch: 2 [156800/163841 (96%)]\tLoss: 0.021581\n",
            "Train Epoch: 2 [157440/163841 (96%)]\tLoss: 0.082431\n",
            "Train Epoch: 2 [158080/163841 (96%)]\tLoss: 0.020819\n",
            "Train Epoch: 2 [158720/163841 (97%)]\tLoss: 0.101538\n",
            "Train Epoch: 2 [159360/163841 (97%)]\tLoss: 0.010065\n",
            "Train Epoch: 2 [160000/163841 (98%)]\tLoss: 0.013220\n",
            "Train Epoch: 2 [160640/163841 (98%)]\tLoss: 0.004618\n",
            "Train Epoch: 2 [161280/163841 (98%)]\tLoss: 0.083991\n",
            "Train Epoch: 2 [161920/163841 (99%)]\tLoss: 0.001684\n",
            "Train Epoch: 2 [162560/163841 (99%)]\tLoss: 0.013484\n",
            "Train Epoch: 2 [163200/163841 (100%)]\tLoss: 0.009864\n",
            "Train Epoch: 2 [2560/163841 (100%)]\tLoss: 0.029923\n",
            "\n",
            "Test set: Average loss: 0.0002, Accuracy: 163132/163841 (100%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(model, device, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "            all_predictions.extend(pred.cpu().numpy().flatten())\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "\n",
        "    all_targets = np.array(all_targets)\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    rmse = np.sqrt(mean_squared_error(all_targets, all_predictions))\n",
        "    mae = mean_absolute_error(all_targets, all_predictions)\n",
        "\n",
        "    print(f'\\nOverall Accuracy: {accuracy:.2f}%')\n",
        "    print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
        "    print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
        "\n",
        "    return accuracy, rmse, mae\n",
        "\n",
        "accuracy, rmse, mae = calculate_metrics(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRLpazMD1JUl",
        "outputId": "5dbaa815-4be5-4c21-e46e-8c1d1a0f124c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall Accuracy: 99.57%\n",
            "Root Mean Squared Error (RMSE): 0.4423\n",
            "Mean Absolute Error (MAE): 0.0239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4SstIPkoPaFF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}